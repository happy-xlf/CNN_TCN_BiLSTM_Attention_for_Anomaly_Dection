{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23baf4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import glob\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import  torch.optim as optim\n",
    "from    matplotlib import pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "plt.rc('font',family='Times New Roman', size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c3318f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e05c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_2d(df_dup):\n",
    "    data_frame = pd.DataFrame()\n",
    "    for i in range(0, df_dup.shape[0]-59):\n",
    "        is_anomaly = False\n",
    "        mylist = []\n",
    "        for j in range(i, i+60):\n",
    "            mylist.append(df_dup['value'].iat[j])\n",
    "            if df_dup['is_anomaly'].iat[j] == 1:\n",
    "                is_anomaly = True\n",
    "        if is_anomaly:\n",
    "            mylist.append(1)\n",
    "        else:\n",
    "            mylist.append(0)\n",
    "        np_Array = np.array(mylist)\n",
    "        mylist = np_Array.T\n",
    "        data_frame = data_frame.append(pd.Series(mylist), ignore_index=True)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ec4c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    dataset_conc=[]\n",
    "    path=r'Dataset'\n",
    "    all_files=glob.glob(path+\"/*.csv\")\n",
    "    for filename in all_files:\n",
    "        df=pd.read_csv(filename,index_col=None,header=0)\n",
    "        #将数据中value为0的替换成NaN\n",
    "        df=df.replace(0,np.nan)\n",
    "        #处理value那层数据，将0去除掉\n",
    "        df=df.dropna(axis=0, how='any',subset=['value'])\n",
    "        df.value = preprocessing.normalize([df.value]).T\n",
    "        dataset_conc.append(convert_2d(df))\n",
    "    frame=pd.concat(dataset_conc,axis=0,ignore_index=True)\n",
    "    y = frame.iloc[:, 60]\n",
    "    X = frame.iloc[:, 0:60]\n",
    "    X_train = X[:int(X.shape[0] * 0.7)]\n",
    "    X_test = X[int(X.shape[0] * 0.7):]\n",
    "    y_train = y[:int(X.shape[0] * 0.7)]\n",
    "    y_test = y[int(X.shape[0] * 0.7):]\n",
    "\n",
    "\n",
    "    X_train = X_train.to_numpy()\n",
    "    nrows, ncols = X_train.shape\n",
    "    X_train = X_train.reshape(nrows, ncols, 1)\n",
    "\n",
    "    X_test = X_test.to_numpy()\n",
    "    nrows, ncols = X_test.shape\n",
    "    X_test = X_test.reshape(nrows, ncols, 1)\n",
    "\n",
    "    y_test = y_test.to_numpy()\n",
    "    # print(\"X_train:\",X_train.shape)\n",
    "    #[62107,60,1]\n",
    "    # print(\"y_train:\",y_train.shape)\n",
    "    #[62107,]\n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaf05e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_test,y_test=get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f00ee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义实现因果卷积的类\n",
    "from torch.nn.utils import weight_norm\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "# 定义了一个残差模块\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        # n_inputs:输入通道数\n",
    "        # n_outputs:输出通道数\n",
    "        # stride：步长\n",
    "        # padding:填充长度\n",
    "        # dilation：扩张率\n",
    "        # 定义第一个空洞卷积层\n",
    "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        # 根据第一个卷积层的输出与padding大小实现因果卷积\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        # 添加激活函数与dropout正则化方法完成第一个卷积\n",
    "        self.relu1 = nn.Softplus()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        # 堆叠同样结构的第二个卷积层\n",
    "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.Softplus()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        # 将卷积模块的所有组建通过Sequential方法依次堆叠在一起\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "\n",
    "        # 如果输出纬度和输入维度不一致，则必须对输出进行1X1卷积\n",
    "        # 如果通道数不一样，那么需要对输入x做一个逐元素的一维卷积以使得它的纬度与前面两个卷积相等。\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.Softplus()\n",
    "        # 不同激活函数的尝试\n",
    "        # self.sigmod = nn.Softmax()\n",
    "        # self.tanh = nn.Tanh()\n",
    "        # self.softPlus = nn.Softplus()\n",
    "        # self.leaky = nn.LeakyReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    # 初始化为从均值为0，标准差为0.01的正态分布中采样的随机值\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    # 结合卷积与输入的恒等映射（或输入的逐元素卷积），并投入ReLU 激活函数完成残差模块\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "# 时间卷积网络\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=5, dropout=0.5):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        # num_input:输入特征数，默认为1\n",
    "        # num_levels:网络层数，每一层是一个残差块\n",
    "        # num_channels:储存了所有层级的输出通道数\n",
    "        layers = []\n",
    "        # num_channels为各层卷积运算的输出通道数或卷积核数量\n",
    "        num_levels = len(num_channels)\n",
    "        # 空洞卷积的扩张系数若随着网络层级的增加而成指数级增加，则可以增大感受野并不丢弃任何输入序列的元素\n",
    "        # dilation_size根据层级数成指数增加，并从num_channels中抽取每一个残差模块的输入通道数与输出通道数\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
    "        # 将所有残差模块堆叠起来组成一个深度卷积网络\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.network(x)\n",
    "        #print('tcn_shape:',x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7257219",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        self.conv=nn.Sequential(\n",
    "            #[512,1,60]\n",
    "            nn.Conv1d(in_channels=1,out_channels=64,kernel_size=3,stride=1,padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2,stride=2),\n",
    "            #[512,64,30]\n",
    "            nn.Conv1d(in_channels=64,out_channels=64,kernel_size=3,stride=1,padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, stride=2),\n",
    "            #[512,64,15]\n",
    "            nn.Conv1d(in_channels=64,out_channels=64,kernel_size=3,stride=1,padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, stride=2),\n",
    "            #[512,64,7]\n",
    "            TemporalConvNet(64,[64,64,64]),\n",
    "            nn.ReLU(),\n",
    "            #[512,64,30]\n",
    "        )\n",
    "        self.bigru=nn.GRU(input_size=448, hidden_size=64, num_layers=1,batch_first=True,bidirectional=True)\n",
    "        self.fc=nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            #[512,128]\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,2),\n",
    "            #[512,2]\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    def attention_net(self, lstm_output, final_state):\n",
    "        batch_size = len(lstm_output)\n",
    "        hidden = final_state.view(batch_size, -1,\n",
    "                                  1)  # hidden : [batch_size, n_hidden * num_directions(=2), n_layer(=1)]\n",
    "        attn_weights = torch.bmm(lstm_output, hidden).squeeze(2)  # attn_weights : [batch_size, n_step]\n",
    "        soft_attn_weights = F.softmax(attn_weights, 1)\n",
    "\n",
    "        # context : [batch_size, n_hidden * num_directions(=2)]\n",
    "        context = torch.bmm(lstm_output.transpose(1, 2), soft_attn_weights.unsqueeze(2)).squeeze(2)\n",
    "        return context, soft_attn_weights\n",
    "\n",
    "    def forward(self,x):\n",
    "        out=self.conv(x)\n",
    "        out=out.reshape(-1,1,7*64)\n",
    "        #[512,1,960]\n",
    "        out,final_hidden_state=self.bigru(out)\n",
    "        attn_out,attention=self.attention_net(out,final_hidden_state)\n",
    "        #[512,128]\n",
    "        out=self.fc(attn_out)\n",
    "        #[512,2]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56fbafa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list2=[]\n",
    "epoch_list2=[]\n",
    "acc_list2=[]\n",
    "ans_acc_list2=[]\n",
    "train_acc_list2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "342ebefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data\n",
    "from numpy import *\n",
    "def train2(input,y_train,X_test,y_test,new_input,new_y_train):\n",
    "    torch_dataset=Data.TensorDataset(input,y_train)\n",
    "    loader = Data.DataLoader(\n",
    "        dataset=torch_dataset,  # 数据，封装进Data.TensorDataset()类的数据\n",
    "        batch_size=512,  # 每块的大小\n",
    "        shuffle=True,  # 要不要打乱数据 (打乱比较好)\n",
    "        num_workers=0,  # 多进程（multiprocess）来读数据\n",
    "    )\n",
    "    # print(len(loader))\n",
    "    #122\n",
    "    net = Net2()\n",
    "    net=net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
    "    net.train()\n",
    "\n",
    "    for epoch in range(501):\n",
    "        # 在一轮中迭代获取每个batch（把全部的数据分成小块一块块的训练）\n",
    "        net.train()\n",
    "        for step, (batch_x, batch_y) in enumerate(loader):\n",
    "            input=batch_x.to(device)\n",
    "            label=batch_y.to(device)\n",
    "            # print(\"input:\",input.shape)\n",
    "            #[512,1,60]\n",
    "            # print(\"label:\",label.shape)\n",
    "            #[512,2]\n",
    "            y_pred=net(input)\n",
    "            loss = F.binary_cross_entropy(y_pred,label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "#             for p in net.parameters():\n",
    "#               # print(p.grad.norm())                 # 查看参数p的梯度\n",
    "#               torch.nn.utils.clip_grad_norm_(p, 10)  # 将梯度裁剪到小于10\n",
    "            optimizer.step()\n",
    "        flag=False\n",
    "        if epoch%20==0:\n",
    "          flag=True\n",
    "        acc=test(net,X_test,y_test,flag)\n",
    "        train_acc=test(net,new_input,new_y_train,flag)\n",
    "        print('epoch', epoch, ':', loss.item(),'train_acc',train_acc,'test_acc：',acc)\n",
    "        acc_list2.append(acc)\n",
    "        ans_acc_list2.append(acc)\n",
    "        train_acc_list2.append(train_acc)\n",
    "        loss_list2.append(loss.item())\n",
    "        epoch_list2.append(epoch)\n",
    "        if epoch%100==0:\n",
    "            print(\"acc平均值：\",round(mean(acc_list2),4))\n",
    "            acc_list2.clear()\n",
    "    torch.save(net.state_dict(),'model/net_bigru_attention_params.pth')\n",
    "    plt.plot(epoch_list2,loss_list2,color='red',label='training Loss')\n",
    "    plt.plot(epoch_list2,ans_acc_list2,color='green',label='test Acc')\n",
    "    plt.plot(epoch_list2,train_acc_list2,color='blue',label='training Acc')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09878799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,x_test,y_test,flag):\n",
    "    model.eval()\n",
    "    torch_dataset=Data.TensorDataset(x_test,y_test)\n",
    "    loader = Data.DataLoader(\n",
    "        dataset=torch_dataset,  # 数据，封装进Data.TensorDataset()类的数据\n",
    "        batch_size=512,  # 每块的大小\n",
    "        num_workers=0,  # 多进程（multiprocess）来读数据\n",
    "    )\n",
    "\n",
    "    acc = 0.0\n",
    "    count = 0\n",
    "    ans_labels=[]\n",
    "    ans_pre=[]\n",
    "    for index, data in enumerate(loader):\n",
    "        inputs, labels = data  # 5,3,400,600  5,10\n",
    "        count += len(labels)\n",
    "        inputs=inputs.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predict = torch.max(outputs, 1)\n",
    "        acc += (labels == predict).sum().item()\n",
    "        ans_labels+=labels.cpu().numpy().tolist()\n",
    "        ans_pre+=predict.cpu().numpy().tolist()\n",
    "    #evaluate performance\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "    if flag==True:\n",
    "      Confusion_Matrix = confusion_matrix(ans_labels, ans_pre)\n",
    "      Accuracy = accuracy_score(ans_labels, ans_pre)\n",
    "      precision = precision_score(ans_labels, ans_pre, average='binary')\n",
    "      recall = recall_score(ans_labels, ans_pre, average='binary')\n",
    "      F1_Score = f1_score(ans_labels, ans_pre, average='binary')\n",
    "      print(\"Confusion_Matrix\")\n",
    "      print(Confusion_Matrix)\n",
    "      print(\"Accuracy \", Accuracy)\n",
    "      print(\"Precision \", precision)\n",
    "      print(\"recall \", recall)\n",
    "      print(\"f1_score \", F1_Score)\n",
    "    return round(acc/count,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8d83123",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_train=y_train\n",
    "new_y_train=torch.tensor(new_y_train)\n",
    "new_x_train=X_train\n",
    "new_input=torch.tensor(new_x_train).permute(0,2,1).to(torch.float32)\n",
    "y_train=F.one_hot(torch.tensor(y_train).to(torch.int64),2)\n",
    "y_train=y_train.to(torch.float32)\n",
    "#[batch_size,seq_len,embedding_size]=>[batch_size,embeding_size,seq_len]\n",
    "input=torch.tensor(X_train).permute(0,2,1).to(torch.float32)\n",
    "X_test = torch.tensor(X_test).permute(0, 2, 1).to(torch.float32)\n",
    "y_test=torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "406393c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\code_software\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion_Matrix\n",
      "[[23986     0]\n",
      " [ 2632     0]]\n",
      "Accuracy  0.9011195431662784\n",
      "Precision  0.0\n",
      "recall  0.0\n",
      "f1_score  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\code_software\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion_Matrix\n",
      "[[56266     0]\n",
      " [ 5841     0]]\n",
      "Accuracy  0.9059526301383097\n",
      "Precision  0.0\n",
      "recall  0.0\n",
      "f1_score  0.0\n",
      "epoch 0 : 0.37405428290367126 train_acc 0.906 test_acc： 0.9011\n",
      "acc平均值： 0.9011\n",
      "epoch 1 : 0.31805479526519775 train_acc 0.906 test_acc： 0.9011\n",
      "epoch 2 : 0.20099034905433655 train_acc 0.906 test_acc： 0.9011\n",
      "epoch 3 : 0.28842297196388245 train_acc 0.906 test_acc： 0.9011\n",
      "epoch 4 : 0.2887352705001831 train_acc 0.906 test_acc： 0.9011\n",
      "epoch 5 : 0.3325498104095459 train_acc 0.906 test_acc： 0.9011\n",
      "epoch 6 : 0.24375571310520172 train_acc 0.906 test_acc： 0.9011\n",
      "epoch 7 : 0.2886204123497009 train_acc 0.906 test_acc： 0.9011\n",
      "epoch 8 : 0.34744301438331604 train_acc 0.906 test_acc： 0.9011\n",
      "epoch 9 : 0.24704761803150177 train_acc 0.906 test_acc： 0.9011\n",
      "epoch 10 : 0.29502567648887634 train_acc 0.9169 test_acc： 0.9049\n",
      "epoch 11 : 0.27749526500701904 train_acc 0.921 test_acc： 0.9084\n",
      "epoch 12 : 0.3972311317920685 train_acc 0.923 test_acc： 0.9108\n",
      "epoch 13 : 0.15504147112369537 train_acc 0.9251 test_acc： 0.9125\n",
      "epoch 14 : 0.2603702247142792 train_acc 0.9259 test_acc： 0.9133\n",
      "epoch 15 : 0.23328369855880737 train_acc 0.9265 test_acc： 0.9148\n",
      "epoch 16 : 0.21521379053592682 train_acc 0.9272 test_acc： 0.9152\n",
      "epoch 17 : 0.2883665859699249 train_acc 0.9275 test_acc： 0.9158\n",
      "epoch 18 : 0.23169097304344177 train_acc 0.9281 test_acc： 0.9164\n",
      "epoch 19 : 0.2459193468093872 train_acc 0.9288 test_acc： 0.918\n",
      "Confusion_Matrix\n",
      "[[23884   102]\n",
      " [ 2024   608]]\n",
      "Accuracy  0.9201292358554362\n",
      "Precision  0.856338028169014\n",
      "recall  0.23100303951367782\n",
      "f1_score  0.36385397965290245\n",
      "Confusion_Matrix\n",
      "[[56094   172]\n",
      " [ 4303  1538]]\n",
      "Accuracy  0.927946930297712\n",
      "Precision  0.8994152046783626\n",
      "recall  0.2633110768703989\n",
      "f1_score  0.4073632631439545\n",
      "epoch 20 : 0.2659580707550049 train_acc 0.9279 test_acc： 0.9201\n",
      "epoch 21 : 0.25600478053092957 train_acc 0.9287 test_acc： 0.9204\n",
      "epoch 22 : 0.2715568244457245 train_acc 0.9286 test_acc： 0.9209\n",
      "epoch 23 : 0.327158659696579 train_acc 0.9294 test_acc： 0.9212\n",
      "epoch 24 : 0.17831280827522278 train_acc 0.9291 test_acc： 0.9219\n",
      "epoch 25 : 0.2963012158870697 train_acc 0.9292 test_acc： 0.9224\n",
      "epoch 26 : 0.25314784049987793 train_acc 0.9296 test_acc： 0.9217\n",
      "epoch 27 : 0.34441474080085754 train_acc 0.9289 test_acc： 0.9219\n",
      "epoch 28 : 0.2262418419122696 train_acc 0.9299 test_acc： 0.9214\n",
      "epoch 29 : 0.2117161601781845 train_acc 0.9291 test_acc： 0.9221\n",
      "epoch 30 : 0.23517465591430664 train_acc 0.9296 test_acc： 0.9216\n",
      "epoch 31 : 0.2951356768608093 train_acc 0.9298 test_acc： 0.9213\n",
      "epoch 32 : 0.2319442182779312 train_acc 0.9298 test_acc： 0.9214\n",
      "epoch 33 : 0.1476074457168579 train_acc 0.9301 test_acc： 0.921\n",
      "epoch 34 : 0.2666289210319519 train_acc 0.9296 test_acc： 0.9226\n",
      "epoch 35 : 0.24030640721321106 train_acc 0.9296 test_acc： 0.9225\n",
      "epoch 36 : 0.2737322449684143 train_acc 0.9296 test_acc： 0.9222\n",
      "epoch 37 : 0.31625208258628845 train_acc 0.9296 test_acc： 0.9228\n",
      "epoch 38 : 0.29058218002319336 train_acc 0.9298 test_acc： 0.9222\n",
      "epoch 39 : 0.2637988030910492 train_acc 0.9289 test_acc： 0.9229\n",
      "Confusion_Matrix\n",
      "[[23895    91]\n",
      " [ 1958   674]]\n",
      "Accuracy  0.9230220151776993\n",
      "Precision  0.8810457516339869\n",
      "recall  0.2560790273556231\n",
      "f1_score  0.39682072416838393\n",
      "Confusion_Matrix\n",
      "[[56020   246]\n",
      " [ 4107  1734]]\n",
      "Accuracy  0.9299112821421096\n",
      "Precision  0.8757575757575757\n",
      "recall  0.2968669748330765\n",
      "f1_score  0.4434215573456079\n",
      "epoch 40 : 0.2559780478477478 train_acc 0.9299 test_acc： 0.923\n",
      "epoch 41 : 0.2591676115989685 train_acc 0.9302 test_acc： 0.9228\n",
      "epoch 42 : 0.24928148090839386 train_acc 0.9306 test_acc： 0.9233\n",
      "epoch 43 : 0.25612759590148926 train_acc 0.9305 test_acc： 0.923\n",
      "epoch 44 : 0.2717715799808502 train_acc 0.9304 test_acc： 0.923\n",
      "epoch 45 : 0.22333462536334991 train_acc 0.9307 test_acc： 0.9228\n",
      "epoch 46 : 0.18765896558761597 train_acc 0.9302 test_acc： 0.923\n",
      "epoch 47 : 0.2513984739780426 train_acc 0.9307 test_acc： 0.9223\n",
      "epoch 48 : 0.17723071575164795 train_acc 0.9311 test_acc： 0.923\n",
      "epoch 49 : 0.26084136962890625 train_acc 0.9306 test_acc： 0.923\n",
      "epoch 50 : 0.32479041814804077 train_acc 0.931 test_acc： 0.9232\n",
      "epoch 51 : 0.2501583397388458 train_acc 0.9312 test_acc： 0.9232\n",
      "epoch 52 : 0.2350033074617386 train_acc 0.9311 test_acc： 0.9228\n",
      "epoch 53 : 0.1920739710330963 train_acc 0.9313 test_acc： 0.9235\n",
      "epoch 54 : 0.24197739362716675 train_acc 0.9311 test_acc： 0.9236\n",
      "epoch 55 : 0.28526484966278076 train_acc 0.9315 test_acc： 0.9233\n",
      "epoch 56 : 0.28001123666763306 train_acc 0.9313 test_acc： 0.9226\n",
      "epoch 57 : 0.17920945584774017 train_acc 0.9317 test_acc： 0.9226\n",
      "epoch 58 : 0.16336238384246826 train_acc 0.9309 test_acc： 0.9232\n",
      "epoch 59 : 0.23373648524284363 train_acc 0.9316 test_acc： 0.923\n",
      "Confusion_Matrix\n",
      "[[23887    99]\n",
      " [ 1955   677]]\n",
      "Accuracy  0.9228341723645653\n",
      "Precision  0.8724226804123711\n",
      "recall  0.2572188449848024\n",
      "f1_score  0.397300469483568\n",
      "Confusion_Matrix\n",
      "[[56028   238]\n",
      " [ 4016  1825]]\n",
      "Accuracy  0.9315053053601043\n",
      "Precision  0.8846340281143965\n",
      "recall  0.31244649888717685\n",
      "f1_score  0.46179149797570845\n",
      "epoch 60 : 0.23494218289852142 train_acc 0.9315 test_acc： 0.9228\n",
      "epoch 61 : 0.19753077626228333 train_acc 0.9312 test_acc： 0.9228\n",
      "epoch 62 : 0.266223669052124 train_acc 0.9309 test_acc： 0.9236\n",
      "epoch 63 : 0.2017798274755478 train_acc 0.9317 test_acc： 0.9225\n",
      "epoch 64 : 0.16603420674800873 train_acc 0.9319 test_acc： 0.9228\n",
      "epoch 65 : 0.2456904947757721 train_acc 0.9311 test_acc： 0.9231\n",
      "epoch 66 : 0.221897691488266 train_acc 0.932 test_acc： 0.9238\n",
      "epoch 67 : 0.23682521283626556 train_acc 0.9324 test_acc： 0.9232\n",
      "epoch 68 : 0.24927663803100586 train_acc 0.9323 test_acc： 0.923\n",
      "epoch 69 : 0.19495916366577148 train_acc 0.9324 test_acc： 0.9235\n",
      "epoch 70 : 0.1423126459121704 train_acc 0.9328 test_acc： 0.9237\n",
      "epoch 71 : 0.38499101996421814 train_acc 0.9322 test_acc： 0.9225\n",
      "epoch 72 : 0.18291811645030975 train_acc 0.9326 test_acc： 0.9223\n",
      "epoch 73 : 0.22796522080898285 train_acc 0.9317 test_acc： 0.9237\n",
      "epoch 74 : 0.33127933740615845 train_acc 0.9322 test_acc： 0.9229\n",
      "epoch 75 : 0.20630942285060883 train_acc 0.9329 test_acc： 0.9236\n",
      "epoch 76 : 0.2388657033443451 train_acc 0.9327 test_acc： 0.9229\n",
      "epoch 77 : 0.18603664636611938 train_acc 0.9319 test_acc： 0.9235\n",
      "epoch 78 : 0.2571079432964325 train_acc 0.9331 test_acc： 0.9232\n",
      "epoch 79 : 0.17315922677516937 train_acc 0.9325 test_acc： 0.9239\n",
      "Confusion_Matrix\n",
      "[[23858   128]\n",
      " [ 1923   709]]\n",
      "Accuracy  0.9229468780524457\n",
      "Precision  0.8470728793309439\n",
      "recall  0.2693768996960486\n",
      "f1_score  0.4087633323724416\n",
      "Confusion_Matrix\n",
      "[[56000   266]\n",
      " [ 3882  1959]]\n",
      "Accuracy  0.9332120372904825\n",
      "Precision  0.8804494382022472\n",
      "recall  0.33538777606574216\n",
      "f1_score  0.48574262335730223\n",
      "epoch 80 : 0.2669682800769806 train_acc 0.9332 test_acc： 0.9229\n",
      "epoch 81 : 0.1715443879365921 train_acc 0.9318 test_acc： 0.9231\n",
      "epoch 82 : 0.18962377309799194 train_acc 0.9329 test_acc： 0.9238\n",
      "epoch 83 : 0.20729300379753113 train_acc 0.9334 test_acc： 0.9226\n",
      "epoch 84 : 0.29716846346855164 train_acc 0.9334 test_acc： 0.9237\n",
      "epoch 85 : 0.2568943500518799 train_acc 0.9333 test_acc： 0.9231\n",
      "epoch 86 : 0.2892354428768158 train_acc 0.9338 test_acc： 0.9224\n",
      "epoch 87 : 0.11412925273180008 train_acc 0.934 test_acc： 0.9222\n",
      "epoch 88 : 0.27727368474006653 train_acc 0.9332 test_acc： 0.9235\n",
      "epoch 89 : 0.16932743787765503 train_acc 0.9339 test_acc： 0.9235\n",
      "epoch 90 : 0.15751677751541138 train_acc 0.9337 test_acc： 0.9234\n",
      "epoch 91 : 0.24516233801841736 train_acc 0.9339 test_acc： 0.9223\n",
      "epoch 92 : 0.1482461541891098 train_acc 0.9342 test_acc： 0.9225\n",
      "epoch 93 : 0.17915552854537964 train_acc 0.9338 test_acc： 0.9224\n",
      "epoch 94 : 0.1375686377286911 train_acc 0.9337 test_acc： 0.9225\n",
      "epoch 95 : 0.3148011863231659 train_acc 0.9333 test_acc： 0.9222\n",
      "epoch 96 : 0.20411647856235504 train_acc 0.9338 test_acc： 0.9223\n",
      "epoch 97 : 0.14174365997314453 train_acc 0.934 test_acc： 0.9222\n",
      "epoch 98 : 0.29738229513168335 train_acc 0.9345 test_acc： 0.9219\n",
      "epoch 99 : 0.25163570046424866 train_acc 0.9343 test_acc： 0.9223\n",
      "Confusion_Matrix\n",
      "[[23852   134]\n",
      " [ 1907   725]]\n",
      "Accuracy  0.9233225636787137\n",
      "Precision  0.8440046565774156\n",
      "recall  0.2754559270516717\n",
      "f1_score  0.4153537668289888\n",
      "Confusion_Matrix\n",
      "[[56018   248]\n",
      " [ 3799  2042]]\n",
      "Accuracy  0.9348382629977298\n",
      "Precision  0.891703056768559\n",
      "recall  0.34959767163156996\n",
      "f1_score  0.5022752428975527\n",
      "epoch 100 : 0.14427199959754944 train_acc 0.9348 test_acc： 0.9233\n",
      "acc平均值： 0.9198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101 : 0.1308821439743042 train_acc 0.9347 test_acc： 0.9222\n",
      "epoch 102 : 0.32292431592941284 train_acc 0.935 test_acc： 0.9218\n",
      "epoch 103 : 0.16169528663158417 train_acc 0.9348 test_acc： 0.9225\n",
      "epoch 104 : 0.3055051565170288 train_acc 0.9352 test_acc： 0.9228\n",
      "epoch 105 : 0.21298013627529144 train_acc 0.9355 test_acc： 0.9237\n",
      "epoch 106 : 0.2116125226020813 train_acc 0.9345 test_acc： 0.9219\n",
      "epoch 107 : 0.26825547218322754 train_acc 0.9351 test_acc： 0.9216\n",
      "epoch 108 : 0.12799771130084991 train_acc 0.9358 test_acc： 0.9214\n",
      "epoch 109 : 0.2421758770942688 train_acc 0.9354 test_acc： 0.9213\n",
      "epoch 110 : 0.1863051801919937 train_acc 0.9358 test_acc： 0.9226\n",
      "epoch 111 : 0.16714704036712646 train_acc 0.9353 test_acc： 0.923\n",
      "epoch 112 : 0.13833576440811157 train_acc 0.936 test_acc： 0.9221\n",
      "epoch 113 : 0.17058491706848145 train_acc 0.9356 test_acc： 0.9229\n",
      "epoch 114 : 0.2677125930786133 train_acc 0.9366 test_acc： 0.9225\n",
      "epoch 115 : 0.1825258433818817 train_acc 0.9359 test_acc： 0.9216\n",
      "epoch 116 : 0.20130711793899536 train_acc 0.9363 test_acc： 0.9227\n",
      "epoch 117 : 0.2353402078151703 train_acc 0.9364 test_acc： 0.9224\n",
      "epoch 118 : 0.21134431660175323 train_acc 0.936 test_acc： 0.9218\n",
      "epoch 119 : 0.2067154347896576 train_acc 0.9364 test_acc： 0.9224\n",
      "Confusion_Matrix\n",
      "[[23813   173]\n",
      " [ 1919   713]]\n",
      "Accuracy  0.9214065669847472\n",
      "Precision  0.8047404063205418\n",
      "recall  0.2708966565349544\n",
      "f1_score  0.4053439454235361\n",
      "Confusion_Matrix\n",
      "[[56047   219]\n",
      " [ 3732  2109]]\n",
      "Accuracy  0.9363839824818458\n",
      "Precision  0.9059278350515464\n",
      "recall  0.3610683102208526\n",
      "f1_score  0.5163422695556372\n",
      "epoch 120 : 0.23766553401947021 train_acc 0.9364 test_acc： 0.9214\n",
      "epoch 121 : 0.18750037252902985 train_acc 0.9368 test_acc： 0.9226\n",
      "epoch 122 : 0.1822563111782074 train_acc 0.937 test_acc： 0.9219\n",
      "epoch 123 : 0.1419283151626587 train_acc 0.9374 test_acc： 0.922\n",
      "epoch 124 : 0.2875552475452423 train_acc 0.9374 test_acc： 0.9222\n",
      "epoch 125 : 0.21045590937137604 train_acc 0.9373 test_acc： 0.9229\n",
      "epoch 126 : 0.16944484412670135 train_acc 0.9374 test_acc： 0.922\n",
      "epoch 127 : 0.17786520719528198 train_acc 0.9373 test_acc： 0.923\n",
      "epoch 128 : 0.1927204430103302 train_acc 0.9379 test_acc： 0.9226\n",
      "epoch 129 : 0.1963263750076294 train_acc 0.9379 test_acc： 0.9232\n",
      "epoch 130 : 0.22786876559257507 train_acc 0.9374 test_acc： 0.9222\n",
      "epoch 131 : 0.2242913693189621 train_acc 0.9386 test_acc： 0.9232\n",
      "epoch 132 : 0.18862685561180115 train_acc 0.9379 test_acc： 0.9221\n",
      "epoch 133 : 0.20629148185253143 train_acc 0.9381 test_acc： 0.9221\n",
      "epoch 134 : 0.24951152503490448 train_acc 0.9388 test_acc： 0.9236\n",
      "epoch 135 : 0.2859411835670471 train_acc 0.9385 test_acc： 0.9232\n",
      "epoch 136 : 0.1584777981042862 train_acc 0.9384 test_acc： 0.922\n",
      "epoch 137 : 0.14075767993927002 train_acc 0.9386 test_acc： 0.9225\n",
      "epoch 138 : 0.10123861581087112 train_acc 0.9389 test_acc： 0.9218\n",
      "epoch 139 : 0.18868158757686615 train_acc 0.9397 test_acc： 0.9229\n",
      "Confusion_Matrix\n",
      "[[23853   133]\n",
      " [ 1907   725]]\n",
      "Accuracy  0.9233601322413404\n",
      "Precision  0.844988344988345\n",
      "recall  0.2754559270516717\n",
      "f1_score  0.41547277936962745\n",
      "Confusion_Matrix\n",
      "[[56161   105]\n",
      " [ 3707  2134]]\n",
      "Accuracy  0.938622055484889\n",
      "Precision  0.9531040643144261\n",
      "recall  0.3653483992467043\n",
      "f1_score  0.5282178217821782\n",
      "epoch 140 : 0.2505604922771454 train_acc 0.9386 test_acc： 0.9234\n",
      "epoch 141 : 0.1958865374326706 train_acc 0.9384 test_acc： 0.9214\n",
      "epoch 142 : 0.15970195829868317 train_acc 0.9392 test_acc： 0.9222\n",
      "epoch 143 : 0.1913791447877884 train_acc 0.9382 test_acc： 0.9216\n",
      "epoch 144 : 0.2152758091688156 train_acc 0.939 test_acc： 0.9216\n",
      "epoch 145 : 0.21340307593345642 train_acc 0.9393 test_acc： 0.922\n",
      "epoch 146 : 0.1810786873102188 train_acc 0.9385 test_acc： 0.9217\n",
      "epoch 147 : 0.1776500940322876 train_acc 0.9398 test_acc： 0.9228\n",
      "epoch 148 : 0.19546326994895935 train_acc 0.9395 test_acc： 0.9219\n",
      "epoch 149 : 0.11997402459383011 train_acc 0.9401 test_acc： 0.9221\n",
      "epoch 150 : 0.1973586231470108 train_acc 0.9402 test_acc： 0.9234\n",
      "epoch 151 : 0.2793753743171692 train_acc 0.94 test_acc： 0.9228\n",
      "epoch 152 : 0.23629669845104218 train_acc 0.9398 test_acc： 0.9232\n",
      "epoch 153 : 0.27215802669525146 train_acc 0.9397 test_acc： 0.9221\n",
      "epoch 154 : 0.22483082115650177 train_acc 0.9398 test_acc： 0.9234\n",
      "epoch 155 : 0.2892057001590729 train_acc 0.9408 test_acc： 0.9231\n",
      "epoch 156 : 0.15455767512321472 train_acc 0.9403 test_acc： 0.9228\n",
      "epoch 157 : 0.16995103657245636 train_acc 0.9412 test_acc： 0.9228\n",
      "epoch 158 : 0.2446797788143158 train_acc 0.9404 test_acc： 0.9221\n",
      "epoch 159 : 0.16270287334918976 train_acc 0.9399 test_acc： 0.9224\n",
      "Confusion_Matrix\n",
      "[[23806   180]\n",
      " [ 1899   733]]\n",
      "Accuracy  0.9218949582988955\n",
      "Precision  0.8028477546549836\n",
      "recall  0.2784954407294833\n",
      "f1_score  0.413540197461213\n",
      "Confusion_Matrix\n",
      "[[56147   119]\n",
      " [ 3565  2276]]\n",
      "Accuracy  0.9406830147970439\n",
      "Precision  0.950313152400835\n",
      "recall  0.3896593049135422\n",
      "f1_score  0.5526954832442934\n",
      "epoch 160 : 0.1899006962776184 train_acc 0.9407 test_acc： 0.9219\n",
      "epoch 161 : 0.18907982110977173 train_acc 0.9409 test_acc： 0.9235\n",
      "epoch 162 : 0.20544150471687317 train_acc 0.9406 test_acc： 0.922\n",
      "epoch 163 : 0.10921542346477509 train_acc 0.9413 test_acc： 0.923\n",
      "epoch 164 : 0.3080502450466156 train_acc 0.9416 test_acc： 0.9228\n",
      "epoch 165 : 0.2198343575000763 train_acc 0.9413 test_acc： 0.9222\n",
      "epoch 166 : 0.1968977302312851 train_acc 0.9416 test_acc： 0.9229\n",
      "epoch 167 : 0.1419011801481247 train_acc 0.9417 test_acc： 0.923\n",
      "epoch 168 : 0.13729265332221985 train_acc 0.9408 test_acc： 0.9228\n",
      "epoch 169 : 0.1926037073135376 train_acc 0.9412 test_acc： 0.9241\n",
      "epoch 170 : 0.27773189544677734 train_acc 0.9411 test_acc： 0.9232\n",
      "epoch 171 : 0.2351274937391281 train_acc 0.9415 test_acc： 0.9228\n",
      "epoch 172 : 0.18807773292064667 train_acc 0.9414 test_acc： 0.9236\n",
      "epoch 173 : 0.22808778285980225 train_acc 0.9422 test_acc： 0.9235\n",
      "epoch 174 : 0.2086271494626999 train_acc 0.9419 test_acc： 0.9228\n",
      "epoch 175 : 0.2284964770078659 train_acc 0.9408 test_acc： 0.9224\n",
      "epoch 176 : 0.19224706292152405 train_acc 0.9423 test_acc： 0.9234\n",
      "epoch 177 : 0.1559647023677826 train_acc 0.9423 test_acc： 0.9229\n",
      "epoch 178 : 0.23524139821529388 train_acc 0.942 test_acc： 0.9237\n",
      "epoch 179 : 0.17765724658966064 train_acc 0.9423 test_acc： 0.9234\n",
      "Confusion_Matrix\n",
      "[[23857   129]\n",
      " [ 1909   723]]\n",
      "Accuracy  0.923435269366594\n",
      "Precision  0.8485915492957746\n",
      "recall  0.27469604863221886\n",
      "f1_score  0.41504018369690016\n",
      "Confusion_Matrix\n",
      "[[56234    32]\n",
      " [ 3634  2207]]\n",
      "Accuracy  0.9409728372003155\n",
      "Precision  0.9857079053148727\n",
      "recall  0.3778462592021914\n",
      "f1_score  0.5462871287128712\n",
      "epoch 180 : 0.2747696042060852 train_acc 0.941 test_acc： 0.9234\n",
      "epoch 181 : 0.1379246711730957 train_acc 0.942 test_acc： 0.9231\n",
      "epoch 182 : 0.14210529625415802 train_acc 0.9417 test_acc： 0.923\n",
      "epoch 183 : 0.2513272762298584 train_acc 0.9423 test_acc： 0.9229\n",
      "epoch 184 : 0.13273707032203674 train_acc 0.9429 test_acc： 0.9229\n",
      "epoch 185 : 0.19980987906455994 train_acc 0.942 test_acc： 0.9232\n",
      "epoch 186 : 0.21203896403312683 train_acc 0.9427 test_acc： 0.9241\n",
      "epoch 187 : 0.22061245143413544 train_acc 0.943 test_acc： 0.9239\n",
      "epoch 188 : 0.19663827121257782 train_acc 0.9427 test_acc： 0.9231\n",
      "epoch 189 : 0.20742763578891754 train_acc 0.9424 test_acc： 0.9234\n",
      "epoch 190 : 0.28641533851623535 train_acc 0.9423 test_acc： 0.9238\n",
      "epoch 191 : 0.15051500499248505 train_acc 0.9432 test_acc： 0.9237\n",
      "epoch 192 : 0.13759756088256836 train_acc 0.9433 test_acc： 0.9234\n",
      "epoch 193 : 0.18560948967933655 train_acc 0.9426 test_acc： 0.9243\n",
      "epoch 194 : 0.11296102404594421 train_acc 0.9433 test_acc： 0.9238\n",
      "epoch 195 : 0.17728030681610107 train_acc 0.9428 test_acc： 0.9231\n",
      "epoch 196 : 0.15162964165210724 train_acc 0.9436 test_acc： 0.9235\n",
      "epoch 197 : 0.21481479704380035 train_acc 0.9434 test_acc： 0.9238\n",
      "epoch 198 : 0.21088699996471405 train_acc 0.9427 test_acc： 0.9244\n",
      "epoch 199 : 0.18876340985298157 train_acc 0.943 test_acc： 0.9238\n",
      "Confusion_Matrix\n",
      "[[23836   150]\n",
      " [ 1863   769]]\n",
      "Accuracy  0.9243744834322639\n",
      "Precision  0.8367791077257889\n",
      "recall  0.29217325227963525\n",
      "f1_score  0.43311743170937766\n",
      "Confusion_Matrix\n",
      "[[56183    83]\n",
      " [ 3457  2384]]\n",
      "Accuracy  0.943001594023218\n",
      "Precision  0.9663558978516417\n",
      "recall  0.4081492895052217\n",
      "f1_score  0.5739046701974001\n",
      "epoch 200 : 0.1766267567873001 train_acc 0.943 test_acc： 0.9244\n",
      "acc平均值： 0.9228\n",
      "epoch 201 : 0.15050476789474487 train_acc 0.9429 test_acc： 0.924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 202 : 0.20891708135604858 train_acc 0.9422 test_acc： 0.9233\n",
      "epoch 203 : 0.21111808717250824 train_acc 0.9426 test_acc： 0.9239\n",
      "epoch 204 : 0.22035130858421326 train_acc 0.9433 test_acc： 0.9236\n",
      "epoch 205 : 0.24885264039039612 train_acc 0.9436 test_acc： 0.9237\n",
      "epoch 206 : 0.17457015812397003 train_acc 0.9428 test_acc： 0.9241\n",
      "epoch 207 : 0.1771167367696762 train_acc 0.9437 test_acc： 0.9239\n",
      "epoch 208 : 0.17397798597812653 train_acc 0.944 test_acc： 0.9234\n",
      "epoch 209 : 0.20875290036201477 train_acc 0.9438 test_acc： 0.9242\n",
      "epoch 210 : 0.18922513723373413 train_acc 0.944 test_acc： 0.9249\n",
      "epoch 211 : 0.192261204123497 train_acc 0.9437 test_acc： 0.9237\n",
      "epoch 212 : 0.1863086074590683 train_acc 0.9439 test_acc： 0.9246\n",
      "epoch 213 : 0.18792735040187836 train_acc 0.9434 test_acc： 0.9237\n",
      "epoch 214 : 0.1935533732175827 train_acc 0.9433 test_acc： 0.924\n",
      "epoch 215 : 0.17239004373550415 train_acc 0.9437 test_acc： 0.9237\n",
      "epoch 216 : 0.16122975945472717 train_acc 0.9435 test_acc： 0.9235\n",
      "epoch 217 : 0.21673549711704254 train_acc 0.944 test_acc： 0.9233\n",
      "epoch 218 : 0.11310318857431412 train_acc 0.9435 test_acc： 0.9245\n",
      "epoch 219 : 0.17010937631130219 train_acc 0.944 test_acc： 0.9237\n",
      "Confusion_Matrix\n",
      "[[23830   156]\n",
      " [ 1849   783]]\n",
      "Accuracy  0.9246750319332783\n",
      "Precision  0.8338658146964856\n",
      "recall  0.29749240121580545\n",
      "f1_score  0.43853262391486975\n",
      "Confusion_Matrix\n",
      "[[56193    73]\n",
      " [ 3383  2458]]\n",
      "Accuracy  0.9443540985718196\n",
      "Precision  0.9711576451995259\n",
      "recall  0.42081835302174286\n",
      "f1_score  0.5871954132823698\n",
      "epoch 220 : 0.1670273244380951 train_acc 0.9444 test_acc： 0.9247\n",
      "epoch 221 : 0.145753875374794 train_acc 0.9442 test_acc： 0.9237\n",
      "epoch 222 : 0.20541808009147644 train_acc 0.9442 test_acc： 0.9228\n",
      "epoch 223 : 0.1950290948152542 train_acc 0.9451 test_acc： 0.9235\n",
      "epoch 224 : 0.21165934205055237 train_acc 0.9443 test_acc： 0.9246\n",
      "epoch 225 : 0.11084412783384323 train_acc 0.9443 test_acc： 0.9238\n",
      "epoch 226 : 0.13893702626228333 train_acc 0.9445 test_acc： 0.9239\n",
      "epoch 227 : 0.19219833612442017 train_acc 0.9451 test_acc： 0.9241\n",
      "epoch 228 : 0.1207057312130928 train_acc 0.9446 test_acc： 0.9241\n",
      "epoch 229 : 0.24195496737957 train_acc 0.9445 test_acc： 0.9233\n",
      "epoch 230 : 0.19725075364112854 train_acc 0.9446 test_acc： 0.9238\n",
      "epoch 231 : 0.12907062470912933 train_acc 0.9448 test_acc： 0.9236\n",
      "epoch 232 : 0.23998960852622986 train_acc 0.9448 test_acc： 0.9244\n",
      "epoch 233 : 0.20644855499267578 train_acc 0.9447 test_acc： 0.9231\n",
      "epoch 234 : 0.16100451350212097 train_acc 0.9443 test_acc： 0.923\n",
      "epoch 235 : 0.21208693087100983 train_acc 0.9451 test_acc： 0.9239\n",
      "epoch 236 : 0.1869628131389618 train_acc 0.9446 test_acc： 0.9231\n",
      "epoch 237 : 0.20872339606285095 train_acc 0.9452 test_acc： 0.9239\n",
      "epoch 238 : 0.17378103733062744 train_acc 0.9455 test_acc： 0.9241\n",
      "epoch 239 : 0.23346827924251556 train_acc 0.9455 test_acc： 0.9213\n",
      "Confusion_Matrix\n",
      "[[23802   184]\n",
      " [ 1849   783]]\n",
      "Accuracy  0.923623112179728\n",
      "Precision  0.8097207859358841\n",
      "recall  0.29749240121580545\n",
      "f1_score  0.4351208669074743\n",
      "Confusion_Matrix\n",
      "[[56222    44]\n",
      " [ 3346  2495]]\n",
      "Accuracy  0.9454167807171494\n",
      "Precision  0.9826703426545884\n",
      "recall  0.4271528847800034\n",
      "f1_score  0.5954653937947494\n",
      "epoch 240 : 0.206381157040596 train_acc 0.9454 test_acc： 0.9236\n",
      "epoch 241 : 0.17322951555252075 train_acc 0.9453 test_acc： 0.9237\n",
      "epoch 242 : 0.11614473164081573 train_acc 0.9455 test_acc： 0.9245\n",
      "epoch 243 : 0.1706991344690323 train_acc 0.9454 test_acc： 0.9238\n",
      "epoch 244 : 0.15172505378723145 train_acc 0.9449 test_acc： 0.9233\n",
      "epoch 245 : 0.13547977805137634 train_acc 0.9449 test_acc： 0.9238\n",
      "epoch 246 : 0.1275438666343689 train_acc 0.9447 test_acc： 0.9247\n",
      "epoch 247 : 0.28878897428512573 train_acc 0.9459 test_acc： 0.924\n",
      "epoch 248 : 0.17494454979896545 train_acc 0.9454 test_acc： 0.9241\n",
      "epoch 249 : 0.22161874175071716 train_acc 0.9462 test_acc： 0.9232\n",
      "epoch 250 : 0.2333366870880127 train_acc 0.9461 test_acc： 0.9235\n",
      "epoch 251 : 0.15310488641262054 train_acc 0.9455 test_acc： 0.9245\n",
      "epoch 252 : 0.11212003231048584 train_acc 0.9457 test_acc： 0.9238\n",
      "epoch 253 : 0.14110849797725677 train_acc 0.9465 test_acc： 0.9235\n",
      "epoch 254 : 0.19430039823055267 train_acc 0.9454 test_acc： 0.9244\n",
      "epoch 255 : 0.22186435759067535 train_acc 0.9455 test_acc： 0.926\n",
      "epoch 256 : 0.13760609924793243 train_acc 0.9456 test_acc： 0.9246\n",
      "epoch 257 : 0.17550794780254364 train_acc 0.9449 test_acc： 0.9242\n",
      "epoch 258 : 0.3249552249908447 train_acc 0.9457 test_acc： 0.9228\n",
      "epoch 259 : 0.13103656470775604 train_acc 0.9458 test_acc： 0.9241\n",
      "Confusion_Matrix\n",
      "[[23700   286]\n",
      " [ 1830   802]]\n",
      "Accuracy  0.9205049214817042\n",
      "Precision  0.7371323529411765\n",
      "recall  0.3047112462006079\n",
      "f1_score  0.4311827956989247\n",
      "Confusion_Matrix\n",
      "[[56185    81]\n",
      " [ 3247  2594]]\n",
      "Accuracy  0.9464150578839744\n",
      "Precision  0.9697196261682243\n",
      "recall  0.4441020373223763\n",
      "f1_score  0.6092062000939408\n",
      "epoch 260 : 0.22226764261722565 train_acc 0.9464 test_acc： 0.9205\n",
      "epoch 261 : 0.2046191394329071 train_acc 0.9465 test_acc： 0.9224\n",
      "epoch 262 : 0.18673986196517944 train_acc 0.9463 test_acc： 0.924\n",
      "epoch 263 : 0.22984261810779572 train_acc 0.947 test_acc： 0.9197\n",
      "epoch 264 : 0.16862636804580688 train_acc 0.9468 test_acc： 0.9217\n",
      "epoch 265 : 0.2701888978481293 train_acc 0.947 test_acc： 0.9202\n",
      "epoch 266 : 0.21123006939888 train_acc 0.9468 test_acc： 0.9224\n",
      "epoch 267 : 0.16883309185504913 train_acc 0.9473 test_acc： 0.9225\n",
      "epoch 268 : 0.17266707122325897 train_acc 0.9482 test_acc： 0.9189\n",
      "epoch 269 : 0.13825079798698425 train_acc 0.9457 test_acc： 0.9236\n",
      "epoch 270 : 0.16968205571174622 train_acc 0.9464 test_acc： 0.9221\n",
      "epoch 271 : 0.15148372948169708 train_acc 0.9467 test_acc： 0.9233\n",
      "epoch 272 : 0.1776989996433258 train_acc 0.9467 test_acc： 0.9241\n",
      "epoch 273 : 0.15053215622901917 train_acc 0.9468 test_acc： 0.9237\n",
      "epoch 274 : 0.1742577999830246 train_acc 0.9474 test_acc： 0.9217\n",
      "epoch 275 : 0.16571128368377686 train_acc 0.947 test_acc： 0.922\n",
      "epoch 276 : 0.21675518155097961 train_acc 0.9479 test_acc： 0.9211\n",
      "epoch 277 : 0.15414537489414215 train_acc 0.9473 test_acc： 0.9211\n",
      "epoch 278 : 0.15765804052352905 train_acc 0.9465 test_acc： 0.9211\n",
      "epoch 279 : 0.12778422236442566 train_acc 0.9472 test_acc： 0.9215\n",
      "Confusion_Matrix\n",
      "[[23726   260]\n",
      " [ 1798   834]]\n",
      "Accuracy  0.9226838981140582\n",
      "Precision  0.7623400365630713\n",
      "recall  0.3168693009118541\n",
      "f1_score  0.4476650563607085\n",
      "Confusion_Matrix\n",
      "[[56220    46]\n",
      " [ 3256  2585]]\n",
      "Accuracy  0.9468336902442559\n",
      "Precision  0.9825161535537819\n",
      "recall  0.4425612052730697\n",
      "f1_score  0.6102455146364495\n",
      "epoch 280 : 0.1303148865699768 train_acc 0.9468 test_acc： 0.9227\n",
      "epoch 281 : 0.1938360333442688 train_acc 0.9478 test_acc： 0.9199\n",
      "epoch 282 : 0.13188983500003815 train_acc 0.9473 test_acc： 0.9187\n",
      "epoch 283 : 0.2058633267879486 train_acc 0.9481 test_acc： 0.921\n",
      "epoch 284 : 0.16740933060646057 train_acc 0.9466 test_acc： 0.9236\n",
      "epoch 285 : 0.23688742518424988 train_acc 0.9483 test_acc： 0.9195\n",
      "epoch 286 : 0.14275795221328735 train_acc 0.9481 test_acc： 0.9192\n",
      "epoch 287 : 0.21435116231441498 train_acc 0.9464 test_acc： 0.9247\n",
      "epoch 288 : 0.08950376510620117 train_acc 0.9488 test_acc： 0.9175\n",
      "epoch 289 : 0.20083589851856232 train_acc 0.9482 test_acc： 0.9204\n",
      "epoch 290 : 0.17817053198814392 train_acc 0.9493 test_acc： 0.9144\n",
      "epoch 291 : 0.13895775377750397 train_acc 0.9486 test_acc： 0.9191\n",
      "epoch 292 : 0.1772756427526474 train_acc 0.9486 test_acc： 0.9178\n",
      "epoch 293 : 0.2270883023738861 train_acc 0.9462 test_acc： 0.9255\n",
      "epoch 294 : 0.12740610539913177 train_acc 0.9481 test_acc： 0.922\n",
      "epoch 295 : 0.16342642903327942 train_acc 0.9487 test_acc： 0.9188\n",
      "epoch 296 : 0.06955517083406448 train_acc 0.9471 test_acc： 0.9229\n",
      "epoch 297 : 0.24504025280475616 train_acc 0.9483 test_acc： 0.918\n",
      "epoch 298 : 0.21298320591449738 train_acc 0.9495 test_acc： 0.9162\n",
      "epoch 299 : 0.21934695541858673 train_acc 0.9487 test_acc： 0.9173\n",
      "Confusion_Matrix\n",
      "[[23645   341]\n",
      " [ 1760   872]]\n",
      "Accuracy  0.921068449921106\n",
      "Precision  0.718878812860676\n",
      "recall  0.331306990881459\n",
      "f1_score  0.45357607282184653\n",
      "Confusion_Matrix\n",
      "[[56132   134]\n",
      " [ 3064  2777]]\n",
      "Accuracy  0.9485082196853817\n",
      "Precision  0.9539677086911714\n",
      "recall  0.47543228899161105\n",
      "f1_score  0.6345978062157221\n",
      "epoch 300 : 0.15078431367874146 train_acc 0.9485 test_acc： 0.9211\n",
      "acc平均值： 0.9226\n",
      "epoch 301 : 0.2087946981191635 train_acc 0.9475 test_acc： 0.9241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 302 : 0.11848825961351395 train_acc 0.9489 test_acc： 0.9229\n",
      "epoch 303 : 0.1765628457069397 train_acc 0.9488 test_acc： 0.9229\n",
      "epoch 304 : 0.08378224074840546 train_acc 0.9481 test_acc： 0.9228\n",
      "epoch 305 : 0.18347707390785217 train_acc 0.9504 test_acc： 0.9195\n",
      "epoch 306 : 0.23538650572299957 train_acc 0.949 test_acc： 0.921\n",
      "epoch 307 : 0.15197308361530304 train_acc 0.9502 test_acc： 0.918\n",
      "epoch 308 : 0.19237473607063293 train_acc 0.9498 test_acc： 0.918\n",
      "epoch 309 : 0.17310160398483276 train_acc 0.9495 test_acc： 0.9185\n",
      "epoch 310 : 0.15058773756027222 train_acc 0.9491 test_acc： 0.9229\n",
      "epoch 311 : 0.125021293759346 train_acc 0.9504 test_acc： 0.9142\n",
      "epoch 312 : 0.2014976292848587 train_acc 0.9504 test_acc： 0.9166\n",
      "epoch 313 : 0.09863549470901489 train_acc 0.9491 test_acc： 0.9211\n",
      "epoch 314 : 0.10148365795612335 train_acc 0.9507 test_acc： 0.9201\n",
      "epoch 315 : 0.19557441771030426 train_acc 0.949 test_acc： 0.9202\n",
      "epoch 316 : 0.17357061803340912 train_acc 0.9503 test_acc： 0.9185\n",
      "epoch 317 : 0.1709841787815094 train_acc 0.9493 test_acc： 0.9217\n",
      "epoch 318 : 0.1041770651936531 train_acc 0.9486 test_acc： 0.9238\n",
      "epoch 319 : 0.1733267903327942 train_acc 0.9494 test_acc： 0.9212\n",
      "Confusion_Matrix\n",
      "[[23649   337]\n",
      " [ 1803   829]]\n",
      "Accuracy  0.9196032759786611\n",
      "Precision  0.7109777015437393\n",
      "recall  0.3149696048632219\n",
      "f1_score  0.43654555028962616\n",
      "Confusion_Matrix\n",
      "[[56199    67]\n",
      " [ 3069  2772]]\n",
      "Accuracy  0.9495064968522067\n",
      "Precision  0.9764001408946812\n",
      "recall  0.4745762711864407\n",
      "f1_score  0.6387096774193548\n",
      "epoch 320 : 0.1359022855758667 train_acc 0.9495 test_acc： 0.9196\n",
      "epoch 321 : 0.20671400427818298 train_acc 0.9509 test_acc： 0.9137\n",
      "epoch 322 : 0.188279390335083 train_acc 0.9497 test_acc： 0.9208\n",
      "epoch 323 : 0.14967836439609528 train_acc 0.9508 test_acc： 0.9213\n",
      "epoch 324 : 0.18736714124679565 train_acc 0.9503 test_acc： 0.9138\n",
      "epoch 325 : 0.16113771498203278 train_acc 0.9499 test_acc： 0.9213\n",
      "epoch 326 : 0.15052908658981323 train_acc 0.951 test_acc： 0.9178\n",
      "epoch 327 : 0.13241665065288544 train_acc 0.9505 test_acc： 0.9213\n",
      "epoch 328 : 0.11593791097402573 train_acc 0.9493 test_acc： 0.9162\n",
      "epoch 329 : 0.19901607930660248 train_acc 0.9497 test_acc： 0.9222\n",
      "epoch 330 : 0.14661791920661926 train_acc 0.9502 test_acc： 0.9208\n",
      "epoch 331 : 0.1044859066605568 train_acc 0.9499 test_acc： 0.9226\n",
      "epoch 332 : 0.1344916969537735 train_acc 0.9521 test_acc： 0.9168\n",
      "epoch 333 : 0.2185768038034439 train_acc 0.9512 test_acc： 0.9173\n",
      "epoch 334 : 0.16722378134727478 train_acc 0.9506 test_acc： 0.9204\n",
      "epoch 335 : 0.1149861067533493 train_acc 0.9505 test_acc： 0.9191\n",
      "epoch 336 : 0.16750556230545044 train_acc 0.9507 test_acc： 0.9214\n",
      "epoch 337 : 0.09054718166589737 train_acc 0.9513 test_acc： 0.9178\n",
      "epoch 338 : 0.14633896946907043 train_acc 0.9494 test_acc： 0.9235\n",
      "epoch 339 : 0.13767895102500916 train_acc 0.9514 test_acc： 0.9164\n",
      "Confusion_Matrix\n",
      "[[23647   339]\n",
      " [ 1805   827]]\n",
      "Accuracy  0.9194530017281539\n",
      "Precision  0.70926243567753\n",
      "recall  0.314209726443769\n",
      "f1_score  0.435492364402317\n",
      "Confusion_Matrix\n",
      "[[56194    72]\n",
      " [ 2934  2907]]\n",
      "Accuracy  0.951599658653614\n",
      "Precision  0.9758308157099698\n",
      "recall  0.49768875192604006\n",
      "f1_score  0.6591836734693878\n",
      "epoch 340 : 0.1210087388753891 train_acc 0.9516 test_acc： 0.9195\n",
      "epoch 341 : 0.17587779462337494 train_acc 0.9521 test_acc： 0.9118\n",
      "epoch 342 : 0.15431885421276093 train_acc 0.9511 test_acc： 0.9198\n",
      "epoch 343 : 0.17558884620666504 train_acc 0.9524 test_acc： 0.9124\n",
      "epoch 344 : 0.16262799501419067 train_acc 0.9523 test_acc： 0.9138\n",
      "epoch 345 : 0.10297660529613495 train_acc 0.9508 test_acc： 0.918\n",
      "epoch 346 : 0.18084610998630524 train_acc 0.9508 test_acc： 0.9152\n",
      "epoch 347 : 0.2022508829832077 train_acc 0.951 test_acc： 0.9164\n",
      "epoch 348 : 0.12815287709236145 train_acc 0.9527 test_acc： 0.9141\n",
      "epoch 349 : 0.08220651745796204 train_acc 0.951 test_acc： 0.9215\n",
      "epoch 350 : 0.18545682728290558 train_acc 0.9515 test_acc： 0.9184\n",
      "epoch 351 : 0.17347131669521332 train_acc 0.9522 test_acc： 0.918\n",
      "epoch 352 : 0.20086167752742767 train_acc 0.9525 test_acc： 0.9169\n",
      "epoch 353 : 0.20619535446166992 train_acc 0.9531 test_acc： 0.917\n",
      "epoch 354 : 0.13596612215042114 train_acc 0.9521 test_acc： 0.9191\n",
      "epoch 355 : 0.08140936493873596 train_acc 0.9538 test_acc： 0.914\n",
      "epoch 356 : 0.22491946816444397 train_acc 0.9514 test_acc： 0.9211\n",
      "epoch 357 : 0.14557065069675446 train_acc 0.9511 test_acc： 0.9165\n",
      "epoch 358 : 0.19440577924251556 train_acc 0.9513 test_acc： 0.9218\n",
      "epoch 359 : 0.11618911474943161 train_acc 0.9532 test_acc： 0.9154\n",
      "Confusion_Matrix\n",
      "[[23641   345]\n",
      " [ 1767   865]]\n",
      "Accuracy  0.9206551957322113\n",
      "Precision  0.7148760330578512\n",
      "recall  0.32864741641337386\n",
      "f1_score  0.450286309213951\n",
      "Confusion_Matrix\n",
      "[[56176    90]\n",
      " [ 2854  2987]]\n",
      "Accuracy  0.952597935820439\n",
      "Precision  0.9707507312317192\n",
      "recall  0.5113850368087656\n",
      "f1_score  0.6698811392688944\n",
      "epoch 360 : 0.1730700433254242 train_acc 0.9526 test_acc： 0.9207\n",
      "epoch 361 : 0.1056312546133995 train_acc 0.9519 test_acc： 0.9164\n",
      "epoch 362 : 0.2600984573364258 train_acc 0.954 test_acc： 0.9104\n",
      "epoch 363 : 0.246004119515419 train_acc 0.9541 test_acc： 0.9066\n",
      "epoch 364 : 0.1505458503961563 train_acc 0.9519 test_acc： 0.9133\n",
      "epoch 365 : 0.16916164755821228 train_acc 0.9523 test_acc： 0.9159\n",
      "epoch 366 : 0.13810046017169952 train_acc 0.9537 test_acc： 0.9116\n",
      "epoch 367 : 0.16470825672149658 train_acc 0.9541 test_acc： 0.9152\n",
      "epoch 368 : 0.23091673851013184 train_acc 0.9526 test_acc： 0.9199\n",
      "epoch 369 : 0.16314825415611267 train_acc 0.954 test_acc： 0.9095\n",
      "epoch 370 : 0.13068030774593353 train_acc 0.9518 test_acc： 0.9177\n",
      "epoch 371 : 0.14397285878658295 train_acc 0.9526 test_acc： 0.9172\n",
      "epoch 372 : 0.160014808177948 train_acc 0.9535 test_acc： 0.9137\n",
      "epoch 373 : 0.13804899156093597 train_acc 0.9522 test_acc： 0.9167\n",
      "epoch 374 : 0.13158920407295227 train_acc 0.9535 test_acc： 0.9151\n",
      "epoch 375 : 0.07953832298517227 train_acc 0.9542 test_acc： 0.915\n",
      "epoch 376 : 0.1680935025215149 train_acc 0.9533 test_acc： 0.9204\n",
      "epoch 377 : 0.09944281727075577 train_acc 0.9537 test_acc： 0.9097\n",
      "epoch 378 : 0.1810622215270996 train_acc 0.9535 test_acc： 0.9137\n",
      "epoch 379 : 0.13288748264312744 train_acc 0.9547 test_acc： 0.9079\n",
      "Confusion_Matrix\n",
      "[[23492   494]\n",
      " [ 1787   845]]\n",
      "Accuracy  0.9143061086482831\n",
      "Precision  0.6310679611650486\n",
      "recall  0.321048632218845\n",
      "f1_score  0.42558549483757246\n",
      "Confusion_Matrix\n",
      "[[56146   120]\n",
      " [ 2755  3086]]\n",
      "Accuracy  0.9537089216996474\n",
      "Precision  0.9625701809107923\n",
      "recall  0.5283341893511385\n",
      "f1_score  0.6822150989278214\n",
      "epoch 380 : 0.11636475473642349 train_acc 0.9537 test_acc： 0.9143\n",
      "epoch 381 : 0.11582286655902863 train_acc 0.9535 test_acc： 0.9169\n",
      "epoch 382 : 0.14816220104694366 train_acc 0.9547 test_acc： 0.915\n",
      "epoch 383 : 0.1752488911151886 train_acc 0.9539 test_acc： 0.914\n",
      "epoch 384 : 0.19761885702610016 train_acc 0.9519 test_acc： 0.9181\n",
      "epoch 385 : 0.11550571024417877 train_acc 0.9542 test_acc： 0.9123\n",
      "epoch 386 : 0.08794451504945755 train_acc 0.9514 test_acc： 0.9181\n",
      "epoch 387 : 0.19034959375858307 train_acc 0.9538 test_acc： 0.9164\n",
      "epoch 388 : 0.15268351137638092 train_acc 0.9556 test_acc： 0.9121\n",
      "epoch 389 : 0.11816797405481339 train_acc 0.9554 test_acc： 0.9142\n",
      "epoch 390 : 0.11857693642377853 train_acc 0.9528 test_acc： 0.9201\n",
      "epoch 391 : 0.2248588353395462 train_acc 0.9529 test_acc： 0.9181\n",
      "epoch 392 : 0.17262892425060272 train_acc 0.9542 test_acc： 0.914\n",
      "epoch 393 : 0.21775679290294647 train_acc 0.9543 test_acc： 0.9167\n",
      "epoch 394 : 0.17287079989910126 train_acc 0.9531 test_acc： 0.9169\n",
      "epoch 395 : 0.15646934509277344 train_acc 0.9531 test_acc： 0.9165\n",
      "epoch 396 : 0.18512572348117828 train_acc 0.9533 test_acc： 0.9201\n",
      "epoch 397 : 0.18506672978401184 train_acc 0.9552 test_acc： 0.9066\n",
      "epoch 398 : 0.2647560238838196 train_acc 0.956 test_acc： 0.9125\n",
      "epoch 399 : 0.16486945748329163 train_acc 0.9537 test_acc： 0.9132\n",
      "Confusion_Matrix\n",
      "[[23461   525]\n",
      " [ 1795   837]]\n",
      "Accuracy  0.9128409347058382\n",
      "Precision  0.6145374449339207\n",
      "recall  0.3180091185410334\n",
      "f1_score  0.4191286930395593\n",
      "Confusion_Matrix\n",
      "[[56086   180]\n",
      " [ 2587  3254]]\n",
      "Accuracy  0.9554478561192781\n",
      "Precision  0.947582993593477\n",
      "recall  0.5570963876048621\n",
      "f1_score  0.7016711590296496\n",
      "epoch 400 : 0.14421147108078003 train_acc 0.9554 test_acc： 0.9128\n",
      "acc平均值： 0.9172\n",
      "epoch 401 : 0.15404237806797028 train_acc 0.9544 test_acc： 0.9179\n",
      "epoch 402 : 0.14917171001434326 train_acc 0.9541 test_acc： 0.9126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 403 : 0.13320209085941315 train_acc 0.9564 test_acc： 0.9053\n",
      "epoch 404 : 0.10552514344453812 train_acc 0.9532 test_acc： 0.9178\n",
      "epoch 405 : 0.15734224021434784 train_acc 0.956 test_acc： 0.9134\n",
      "epoch 406 : 0.17385649681091309 train_acc 0.955 test_acc： 0.9161\n",
      "epoch 407 : 0.11052510142326355 train_acc 0.9551 test_acc： 0.9169\n",
      "epoch 408 : 0.17008502781391144 train_acc 0.9554 test_acc： 0.9133\n",
      "epoch 409 : 0.14919708669185638 train_acc 0.956 test_acc： 0.9133\n",
      "epoch 410 : 0.14691688120365143 train_acc 0.9551 test_acc： 0.917\n",
      "epoch 411 : 0.20217837393283844 train_acc 0.9553 test_acc： 0.9133\n",
      "epoch 412 : 0.105833999812603 train_acc 0.9566 test_acc： 0.9098\n",
      "epoch 413 : 0.11183112114667892 train_acc 0.9548 test_acc： 0.9138\n",
      "epoch 414 : 0.15378853678703308 train_acc 0.9569 test_acc： 0.9098\n",
      "epoch 415 : 0.14406631886959076 train_acc 0.9566 test_acc： 0.9089\n",
      "epoch 416 : 0.11473102122545242 train_acc 0.9548 test_acc： 0.9172\n",
      "epoch 417 : 0.10447058081626892 train_acc 0.9561 test_acc： 0.9127\n",
      "epoch 418 : 0.15308453142642975 train_acc 0.9565 test_acc： 0.9151\n",
      "epoch 419 : 0.15160013735294342 train_acc 0.9562 test_acc： 0.9153\n",
      "Confusion_Matrix\n",
      "[[23369   617]\n",
      " [ 1764   868]]\n",
      "Accuracy  0.9105492523856037\n",
      "Precision  0.5845117845117845\n",
      "recall  0.32978723404255317\n",
      "f1_score  0.4216662618411465\n",
      "Confusion_Matrix\n",
      "[[56055   211]\n",
      " [ 2473  3368]]\n",
      "Accuracy  0.9567842594232534\n",
      "Precision  0.9410449846325789\n",
      "recall  0.5766135935627461\n",
      "f1_score  0.7150743099787686\n",
      "epoch 420 : 0.12009044736623764 train_acc 0.9568 test_acc： 0.9105\n",
      "epoch 421 : 0.1340925693511963 train_acc 0.957 test_acc： 0.9126\n",
      "epoch 422 : 0.14126263558864594 train_acc 0.9586 test_acc： 0.9057\n",
      "epoch 423 : 0.09962961822748184 train_acc 0.9539 test_acc： 0.9186\n",
      "epoch 424 : 0.1562047153711319 train_acc 0.9569 test_acc： 0.9084\n",
      "epoch 425 : 0.17482557892799377 train_acc 0.9559 test_acc： 0.9154\n",
      "epoch 426 : 0.10518476366996765 train_acc 0.9577 test_acc： 0.9101\n",
      "epoch 427 : 0.1119881272315979 train_acc 0.9563 test_acc： 0.9114\n",
      "epoch 428 : 0.13498252630233765 train_acc 0.9558 test_acc： 0.9133\n",
      "epoch 429 : 0.14397773146629333 train_acc 0.9582 test_acc： 0.9092\n",
      "epoch 430 : 0.1347612589597702 train_acc 0.9552 test_acc： 0.9142\n",
      "epoch 431 : 0.06354354321956635 train_acc 0.9545 test_acc： 0.916\n",
      "epoch 432 : 0.13015997409820557 train_acc 0.9579 test_acc： 0.9099\n",
      "epoch 433 : 0.1474999189376831 train_acc 0.9567 test_acc： 0.9151\n",
      "epoch 434 : 0.1438748985528946 train_acc 0.9568 test_acc： 0.9139\n",
      "epoch 435 : 0.16787633299827576 train_acc 0.9585 test_acc： 0.9107\n",
      "epoch 436 : 0.09861653298139572 train_acc 0.9577 test_acc： 0.9148\n",
      "epoch 437 : 0.08916333317756653 train_acc 0.9564 test_acc： 0.9119\n",
      "epoch 438 : 0.11836759001016617 train_acc 0.9559 test_acc： 0.9169\n",
      "epoch 439 : 0.15013138949871063 train_acc 0.9554 test_acc： 0.9173\n",
      "Confusion_Matrix\n",
      "[[23465   521]\n",
      " [ 1785   847]]\n",
      "Accuracy  0.9133668945826132\n",
      "Precision  0.6191520467836257\n",
      "recall  0.32180851063829785\n",
      "f1_score  0.4235\n",
      "Confusion_Matrix\n",
      "[[56128   138]\n",
      " [ 2504  3337]]\n",
      "Accuracy  0.9574605116975542\n",
      "Precision  0.9602877697841726\n",
      "recall  0.57130628317069\n",
      "f1_score  0.7164018892228424\n",
      "epoch 440 : 0.11217557638883591 train_acc 0.9575 test_acc： 0.9134\n",
      "epoch 441 : 0.16422906517982483 train_acc 0.9556 test_acc： 0.9182\n",
      "epoch 442 : 0.10659529268741608 train_acc 0.9586 test_acc： 0.9101\n",
      "epoch 443 : 0.1333005726337433 train_acc 0.9575 test_acc： 0.9173\n",
      "epoch 444 : 0.14286629855632782 train_acc 0.959 test_acc： 0.913\n",
      "epoch 445 : 0.09912281483411789 train_acc 0.957 test_acc： 0.9122\n",
      "epoch 446 : 0.17815928161144257 train_acc 0.9587 test_acc： 0.9124\n",
      "epoch 447 : 0.1494065225124359 train_acc 0.957 test_acc： 0.9146\n",
      "epoch 448 : 0.18001918494701385 train_acc 0.9583 test_acc： 0.9151\n",
      "epoch 449 : 0.1735391914844513 train_acc 0.9593 test_acc： 0.9018\n",
      "epoch 450 : 0.1299685537815094 train_acc 0.9581 test_acc： 0.9097\n",
      "epoch 451 : 0.14289721846580505 train_acc 0.9582 test_acc： 0.9104\n",
      "epoch 452 : 0.07661743462085724 train_acc 0.9565 test_acc： 0.9147\n",
      "epoch 453 : 0.11660055071115494 train_acc 0.9591 test_acc： 0.9105\n",
      "epoch 454 : 0.10048949718475342 train_acc 0.9588 test_acc： 0.9133\n",
      "epoch 455 : 0.1493106633424759 train_acc 0.9601 test_acc： 0.9054\n",
      "epoch 456 : 0.08226427435874939 train_acc 0.9579 test_acc： 0.9176\n",
      "epoch 457 : 0.19619636237621307 train_acc 0.9589 test_acc： 0.9138\n",
      "epoch 458 : 0.14390315115451813 train_acc 0.9601 test_acc： 0.9105\n",
      "epoch 459 : 0.10710229724645615 train_acc 0.9588 test_acc： 0.9136\n",
      "Confusion_Matrix\n",
      "[[23346   640]\n",
      " [ 1784   848]]\n",
      "Accuracy  0.9089338041926516\n",
      "Precision  0.5698924731182796\n",
      "recall  0.3221884498480243\n",
      "f1_score  0.4116504854368932\n",
      "Confusion_Matrix\n",
      "[[56073   193]\n",
      " [ 2317  3524]]\n",
      "Accuracy  0.9595858759882139\n",
      "Precision  0.9480764057035244\n",
      "recall  0.603321349084061\n",
      "f1_score  0.7373927599916301\n",
      "epoch 460 : 0.08681263029575348 train_acc 0.9596 test_acc： 0.9089\n",
      "epoch 461 : 0.09974638372659683 train_acc 0.9607 test_acc： 0.9081\n",
      "epoch 462 : 0.15024574100971222 train_acc 0.9608 test_acc： 0.9125\n",
      "epoch 463 : 0.1652446836233139 train_acc 0.9581 test_acc： 0.9178\n",
      "epoch 464 : 0.11714707314968109 train_acc 0.9582 test_acc： 0.9168\n",
      "epoch 465 : 0.1623961627483368 train_acc 0.9592 test_acc： 0.9128\n",
      "epoch 466 : 0.13166074454784393 train_acc 0.9602 test_acc： 0.905\n",
      "epoch 467 : 0.11881300061941147 train_acc 0.9603 test_acc： 0.9104\n",
      "epoch 468 : 0.1396951675415039 train_acc 0.9602 test_acc： 0.9116\n",
      "epoch 469 : 0.21504415571689606 train_acc 0.9587 test_acc： 0.9151\n",
      "epoch 470 : 0.14065957069396973 train_acc 0.9587 test_acc： 0.9132\n",
      "epoch 471 : 0.18121366202831268 train_acc 0.959 test_acc： 0.9136\n",
      "epoch 472 : 0.16877935826778412 train_acc 0.9613 test_acc： 0.9037\n",
      "epoch 473 : 0.06950026005506516 train_acc 0.9601 test_acc： 0.9118\n",
      "epoch 474 : 0.10412012040615082 train_acc 0.9609 test_acc： 0.9097\n",
      "epoch 475 : 0.07248570770025253 train_acc 0.961 test_acc： 0.9088\n",
      "epoch 476 : 0.15768861770629883 train_acc 0.9577 test_acc： 0.9136\n",
      "epoch 477 : 0.07229489833116531 train_acc 0.9613 test_acc： 0.9038\n",
      "epoch 478 : 0.13192744553089142 train_acc 0.9602 test_acc： 0.9168\n",
      "epoch 479 : 0.09345263987779617 train_acc 0.9603 test_acc： 0.9136\n",
      "Confusion_Matrix\n",
      "[[23456   530]\n",
      " [ 1756   876]]\n",
      "Accuracy  0.9141182658351491\n",
      "Precision  0.6230440967283073\n",
      "recall  0.33282674772036475\n",
      "f1_score  0.43387815750371467\n",
      "Confusion_Matrix\n",
      "[[56086   180]\n",
      " [ 2353  3488]]\n",
      "Accuracy  0.959215547361811\n",
      "Precision  0.95092693565976\n",
      "recall  0.5971580208868345\n",
      "f1_score  0.7336207803133873\n",
      "epoch 480 : 0.16807806491851807 train_acc 0.9592 test_acc： 0.9141\n",
      "epoch 481 : 0.25140172243118286 train_acc 0.9585 test_acc： 0.915\n",
      "epoch 482 : 0.11623433977365494 train_acc 0.9608 test_acc： 0.9036\n",
      "epoch 483 : 0.12050878256559372 train_acc 0.961 test_acc： 0.9098\n",
      "epoch 484 : 0.1763514131307602 train_acc 0.9598 test_acc： 0.9121\n",
      "epoch 485 : 0.1836777627468109 train_acc 0.9604 test_acc： 0.9148\n",
      "epoch 486 : 0.17632204294204712 train_acc 0.9605 test_acc： 0.914\n",
      "epoch 487 : 0.1601289063692093 train_acc 0.9611 test_acc： 0.9142\n",
      "epoch 488 : 0.141215980052948 train_acc 0.9613 test_acc： 0.9139\n",
      "epoch 489 : 0.12791332602500916 train_acc 0.9617 test_acc： 0.9118\n",
      "epoch 490 : 0.0753878578543663 train_acc 0.9613 test_acc： 0.9056\n",
      "epoch 491 : 0.15178723633289337 train_acc 0.9624 test_acc： 0.908\n",
      "epoch 492 : 0.14781169593334198 train_acc 0.9623 test_acc： 0.9105\n",
      "epoch 493 : 0.08150067925453186 train_acc 0.9614 test_acc： 0.913\n",
      "epoch 494 : 0.12898966670036316 train_acc 0.9604 test_acc： 0.9159\n",
      "epoch 495 : 0.10416614264249802 train_acc 0.9618 test_acc： 0.9061\n",
      "epoch 496 : 0.1315603107213974 train_acc 0.9618 test_acc： 0.9044\n",
      "epoch 497 : 0.10169807821512222 train_acc 0.9634 test_acc： 0.9093\n",
      "epoch 498 : 0.15059389173984528 train_acc 0.9605 test_acc： 0.9111\n",
      "epoch 499 : 0.18066811561584473 train_acc 0.9618 test_acc： 0.9109\n",
      "Confusion_Matrix\n",
      "[[23470   516]\n",
      " [ 1767   865]]\n",
      "Accuracy  0.9142309715230296\n",
      "Precision  0.6263577118030412\n",
      "recall  0.32864741641337386\n",
      "f1_score  0.4310989284824321\n",
      "Confusion_Matrix\n",
      "[[56096   170]\n",
      " [ 2262  3579]]\n",
      "Accuracy  0.9608417730690583\n",
      "Precision  0.9546545745532142\n",
      "recall  0.6127375449409348\n",
      "f1_score  0.7464025026068821\n",
      "epoch 500 : 0.1306387186050415 train_acc 0.9608 test_acc： 0.9142\n",
      "acc平均值： 0.9122\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2=train2(input,y_train,X_test,y_test,new_input,new_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5025549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(epoch_list,loss_list,color='red',label='training Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "#plt.plot(epoch_list,ans_acc_list,color='red',label='CNN_TCN_BiLSTM_Attention')\n",
    "plt.plot(epoch_list2,ans_acc_list2,color='blue',label='CNN_TCN_BiGRU_Attention')\n",
    "plt.yticks([0.8,0.85,0.90,0.95,1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc72fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "#plt.plot(epoch_list,loss_list,color='red',label='CNN_TCN_BiLSTM_Attention')\n",
    "plt.plot(epoch_list2,loss_list2,color='blue',label='CNN_TCN_BiGRU_Attention')\n",
    "# plt.yticks([0.8,0.85,0.90,0.95,1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5027a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwt\n",
    "xl = xlwt.Workbook()\n",
    "# 调用对象的add_sheet方法\n",
    "sheet1 = xl.add_sheet('sheet1', cell_overwrite_ok=True)\n",
    "\n",
    "sheet1.write(0, 0, \"cnn_tcn_bigru_attention_accuracy\")\n",
    "sheet1.write(0, 1, 'cnn_tcn_bigru_attention_loss')\n",
    "\n",
    "\n",
    "for i in range(0, len(ans_acc_list2)):\n",
    "    sheet1.write(i + 1, 0, ans_acc_list2[i])\n",
    "    sheet1.write(i + 1, 1, loss_list2[i])\n",
    "\n",
    "xl.save(\"csv/cnn_tcn_bigru_attention.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
