{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9760e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import glob\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import  torch.optim as optim\n",
    "from    matplotlib import pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "plt.rc('font',family='Times New Roman', size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "151215de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6637b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_2d(df_dup):\n",
    "    data_frame = pd.DataFrame()\n",
    "    for i in range(0, df_dup.shape[0]-59):\n",
    "        is_anomaly = False\n",
    "        mylist = []\n",
    "        for j in range(i, i+60):\n",
    "            mylist.append(df_dup['value'].iat[j])\n",
    "            if df_dup['is_anomaly'].iat[j] == 1:\n",
    "                is_anomaly = True\n",
    "        if is_anomaly:\n",
    "            mylist.append(1)\n",
    "        else:\n",
    "            mylist.append(0)\n",
    "        np_Array = np.array(mylist)\n",
    "        mylist = np_Array.T\n",
    "        data_frame = data_frame.append(pd.Series(mylist), ignore_index=True)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e95fa1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    dataset_conc=[]\n",
    "    path=r'../../Dataset'\n",
    "    all_files=glob.glob(path+\"/*.csv\")\n",
    "    for filename in all_files:\n",
    "        df=pd.read_csv(filename,index_col=None,header=0)\n",
    "        #将数据中value为0的替换成NaN\n",
    "        df=df.replace(0,np.nan)\n",
    "        #处理value那层数据，将0去除掉\n",
    "        df=df.dropna(axis=0, how='any',subset=['value'])\n",
    "        df.value = preprocessing.normalize([df.value]).T\n",
    "        dataset_conc.append(convert_2d(df))\n",
    "    frame=pd.concat(dataset_conc,axis=0,ignore_index=True)\n",
    "    y = frame.iloc[:, 60]\n",
    "    X = frame.iloc[:, 0:60]\n",
    "    X_train = X[:int(X.shape[0] * 0.7)]\n",
    "    X_test = X[int(X.shape[0] * 0.7):]\n",
    "    y_train = y[:int(X.shape[0] * 0.7)]\n",
    "    y_test = y[int(X.shape[0] * 0.7):]\n",
    "\n",
    "\n",
    "    X_train = X_train.to_numpy()\n",
    "    nrows, ncols = X_train.shape\n",
    "    X_train = X_train.reshape(nrows, ncols, 1)\n",
    "\n",
    "    X_test = X_test.to_numpy()\n",
    "    nrows, ncols = X_test.shape\n",
    "    X_test = X_test.reshape(nrows, ncols, 1)\n",
    "\n",
    "    y_test = y_test.to_numpy()\n",
    "    # print(\"X_train:\",X_train.shape)\n",
    "    #[62107,60,1]\n",
    "    # print(\"y_train:\",y_train.shape)\n",
    "    #[62107,]\n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61b78944",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_test,y_test=get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ae5e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.tensor(X_test).permute(0, 2, 1).to(torch.float32)\n",
    "y_test=torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69887d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.02393263],\n",
       "        [0.04493904],\n",
       "        [0.05900332],\n",
       "        ...,\n",
       "        [0.0085436 ],\n",
       "        [0.01431762],\n",
       "        [0.01787009]],\n",
       "\n",
       "       [[0.04493904],\n",
       "        [0.05900332],\n",
       "        [0.0459983 ],\n",
       "        ...,\n",
       "        [0.01431762],\n",
       "        [0.01787009],\n",
       "        [0.01376995]],\n",
       "\n",
       "       [[0.05900332],\n",
       "        [0.0459983 ],\n",
       "        [0.02360224],\n",
       "        ...,\n",
       "        [0.01787009],\n",
       "        [0.01376995],\n",
       "        [0.00622143]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.01675279],\n",
       "        [0.01928905],\n",
       "        [0.01928905],\n",
       "        ...,\n",
       "        [0.02671505],\n",
       "        [0.02573092],\n",
       "        [0.02598961]],\n",
       "\n",
       "       [[0.01928905],\n",
       "        [0.01928905],\n",
       "        [0.01689901],\n",
       "        ...,\n",
       "        [0.02573092],\n",
       "        [0.02598961],\n",
       "        [0.02525853]],\n",
       "\n",
       "       [[0.01928905],\n",
       "        [0.01689901],\n",
       "        [0.01999482],\n",
       "        ...,\n",
       "        [0.02598961],\n",
       "        [0.02525853],\n",
       "        [0.02514606]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a513c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data\n",
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b786857e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,x_test,y_test,flag):\n",
    "    model.eval()\n",
    "    torch_dataset=Data.TensorDataset(x_test,y_test)\n",
    "    loader = Data.DataLoader(\n",
    "        dataset=torch_dataset,  # 数据，封装进Data.TensorDataset()类的数据\n",
    "        batch_size=512,  # 每块的大小\n",
    "        num_workers=0,  # 多进程（multiprocess）来读数据\n",
    "    )\n",
    "\n",
    "    acc = 0.0\n",
    "    count = 0\n",
    "    ans_labels=[]\n",
    "    ans_pre=[]\n",
    "    for index, data in enumerate(loader):\n",
    "        inputs, labels = data  # 5,3,400,600  5,10\n",
    "        count += len(labels)\n",
    "        inputs=inputs.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predict = torch.max(outputs, 1)\n",
    "        acc += (labels == predict).sum().item()\n",
    "        ans_labels+=labels.cpu().numpy().tolist()\n",
    "        ans_pre+=predict.cpu().numpy().tolist()\n",
    "    #evaluate performance\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "    if flag==True:\n",
    "      Confusion_Matrix = confusion_matrix(ans_labels, ans_pre)\n",
    "      Accuracy = accuracy_score(ans_labels, ans_pre)\n",
    "      precision = precision_score(ans_labels, ans_pre, average='binary')\n",
    "      recall = recall_score(ans_labels, ans_pre, average='binary')\n",
    "      F1_Score = f1_score(ans_labels, ans_pre, average='binary')\n",
    "      print(\"Confusion_Matrix\")\n",
    "      print(Confusion_Matrix)\n",
    "      print(\"Accuracy \", Accuracy)\n",
    "      print(\"Precision \", precision)\n",
    "      print(\"recall \", recall)\n",
    "      print(\"f1_score \", F1_Score)\n",
    "    return round(acc/count,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afb12b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义实现因果卷积的类\n",
    "from torch.nn.utils import weight_norm\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "# 定义了一个残差模块\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        # n_inputs:输入通道数\n",
    "        # n_outputs:输出通道数\n",
    "        # stride：步长\n",
    "        # padding:填充长度\n",
    "        # dilation：扩张率\n",
    "        # 定义第一个空洞卷积层\n",
    "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        # 根据第一个卷积层的输出与padding大小实现因果卷积\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        # 添加激活函数与dropout正则化方法完成第一个卷积\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        # 堆叠同样结构的第二个卷积层\n",
    "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        # 将卷积模块的所有组建通过Sequential方法依次堆叠在一起\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "\n",
    "        # 如果输出纬度和输入维度不一致，则必须对输出进行1X1卷积\n",
    "        # 如果通道数不一样，那么需要对输入x做一个逐元素的一维卷积以使得它的纬度与前面两个卷积相等。\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        # 不同激活函数的尝试\n",
    "        # self.sigmod = nn.Softmax()\n",
    "        # self.tanh = nn.Tanh()\n",
    "        # self.softPlus = nn.Softplus()\n",
    "        # self.leaky = nn.LeakyReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    # 初始化为从均值为0，标准差为0.01的正态分布中采样的随机值\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    # 结合卷积与输入的恒等映射（或输入的逐元素卷积），并投入ReLU 激活函数完成残差模块\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "# 时间卷积网络\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=5, dropout=0.5):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        # num_input:输入特征数，默认为1\n",
    "        # num_levels:网络层数，每一层是一个残差块\n",
    "        # num_channels:储存了所有层级的输出通道数\n",
    "        layers = []\n",
    "        # num_channels为各层卷积运算的输出通道数或卷积核数量\n",
    "        num_levels = len(num_channels)\n",
    "        # 空洞卷积的扩张系数若随着网络层级的增加而成指数级增加，则可以增大感受野并不丢弃任何输入序列的元素\n",
    "        # dilation_size根据层级数成指数增加，并从num_channels中抽取每一个残差模块的输入通道数与输出通道数\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
    "        # 将所有残差模块堆叠起来组成一个深度卷积网络\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.network(x)\n",
    "        #print('tcn_shape:',x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b09abaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        self.conv=nn.Sequential(\n",
    "            #[512,1,60]\n",
    "            nn.Conv1d(in_channels=1,out_channels=64,kernel_size=3,stride=1,padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2,stride=2),\n",
    "            #[512,32,30]\n",
    "            nn.Conv1d(in_channels=64,out_channels=64,kernel_size=3,stride=1,padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, stride=2),\n",
    "            #[512,64,15]\n",
    "            TemporalConvNet(64,[64,64,64]),\n",
    "            nn.ReLU(),\n",
    "            #[512,64,15]\n",
    "        )\n",
    "        self.bigru=nn.GRU(input_size=960, hidden_size=64, num_layers=1,batch_first=True,bidirectional=True)\n",
    "        self.fc=nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            #[512,128]\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(32,2),\n",
    "            #[512,2]\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    def attention_net(self, lstm_output, final_state):\n",
    "        batch_size = len(lstm_output)\n",
    "        hidden = final_state.view(batch_size, -1,\n",
    "                                  1)  # hidden : [batch_size, n_hidden * num_directions(=2), n_layer(=1)]\n",
    "        attn_weights = torch.bmm(lstm_output, hidden).squeeze(2)  # attn_weights : [batch_size, n_step]\n",
    "        soft_attn_weights = F.softmax(attn_weights, 1)\n",
    "\n",
    "        # context : [batch_size, n_hidden * num_directions(=2)]\n",
    "        context = torch.bmm(lstm_output.transpose(1, 2), soft_attn_weights.unsqueeze(2)).squeeze(2)\n",
    "        return context, soft_attn_weights\n",
    "\n",
    "    def forward(self,x):\n",
    "        out=self.conv(x)\n",
    "        out=out.reshape(-1,1,15*64)\n",
    "        #[512,1,960]\n",
    "        out,final_hidden_state=self.bigru(out)\n",
    "        attn_out,attention=self.attention_net(out,final_hidden_state)\n",
    "        #[512,128]\n",
    "        out=self.fc(attn_out)\n",
    "        #[512,2]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a951037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Net2()\n",
    "model.load_state_dict(torch.load('net_bigru_attention_params.pth'))\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1482ac0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0169, 0.0200, 0.0230,  ..., 0.0253, 0.0251, 0.0310]],\n",
       "\n",
       "        [[0.0200, 0.0230, 0.0204,  ..., 0.0251, 0.0310, 0.0320]],\n",
       "\n",
       "        [[0.0230, 0.0204, 0.0220,  ..., 0.0310, 0.0320, 0.0255]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0156, 0.0135, 0.0143,  ..., 0.0096, 0.0103, 0.0133]],\n",
       "\n",
       "        [[0.0135, 0.0143, 0.0075,  ..., 0.0103, 0.0133, 0.0151]],\n",
       "\n",
       "        [[0.0143, 0.0075, 0.0063,  ..., 0.0133, 0.0151, 0.0203]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cb939ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e80431e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch_dataset=Data.TensorDataset(X_test,y_test)\n",
    "loader = Data.DataLoader(\n",
    "    dataset=torch_dataset,  # 数据，封装进Data.TensorDataset()类的数据\n",
    "    batch_size=512,  # 每块的大小\n",
    "    num_workers=0,  # 多进程（multiprocess）来读数据\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9fcfd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25786\n",
      "0.9687\n",
      "Confusion_Matrix\n",
      "[[23786   200]\n",
      " [  632  2000]]\n",
      "Accuracy  0.9687429558945074\n",
      "Precision  0.9090909090909091\n",
      "recall  0.7598784194528876\n",
      "f1_score  0.8278145695364237\n"
     ]
    }
   ],
   "source": [
    "acc=0\n",
    "count=0\n",
    "ans_labels=[]\n",
    "ans_pre=[]\n",
    "for index, data in enumerate(loader):\n",
    "    inputs, labels = data  # 5,3,400,600  5,10\n",
    "    count += len(labels)\n",
    "    inputs=inputs.to(device)\n",
    "    labels=labels.to(device)\n",
    "    outputs = model(inputs)\n",
    "    _, predict = torch.max(outputs, 1)\n",
    "    acc += (labels == predict).sum().item()\n",
    "    ans_labels+=labels.cpu().numpy().tolist()\n",
    "    ans_pre+=predict.cpu().numpy().tolist()\n",
    "\n",
    "print(acc)\n",
    "print(round(acc/count,4))\n",
    "#evaluate performance\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "Confusion_Matrix = confusion_matrix(ans_labels, ans_pre)\n",
    "Accuracy = accuracy_score(ans_labels, ans_pre)\n",
    "precision = precision_score(ans_labels, ans_pre, average='binary')\n",
    "recall = recall_score(ans_labels, ans_pre, average='binary')\n",
    "F1_Score = f1_score(ans_labels, ans_pre, average='binary')\n",
    "print(\"Confusion_Matrix\")\n",
    "print(Confusion_Matrix)\n",
    "print(\"Accuracy \", Accuracy)\n",
    "print(\"Precision \", precision)\n",
    "print(\"recall \", recall)\n",
    "print(\"f1_score \", F1_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb7e6296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26618"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ans_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebff8afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.xlabel(\"Nums\")\n",
    "plt.ylabel(\"Value\")\n",
    "epoch_list=list(range(170,180))\n",
    "plt.plot(epoch_list,ans_pre[170:180],color='green',label='ans_pre')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6bad8d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 117, '1': 113, '2': 87, '3': 102, '4': 99, '5': 114}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 50, 572)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "k=math.ceil(len(ans_pre)/10)\n",
    "count_mp={'0':0,'1':0,'2':0,'3':0,'4':0,'5':0}\n",
    "w=0\n",
    "point=0\n",
    "context=0\n",
    "collective=0\n",
    "for i in range(k):\n",
    "    cnt=0\n",
    "    t=i%6\n",
    "    for k in range(w,min(w+10,len(ans_pre))):\n",
    "        if ans_pre[k]==0 and ans_labels[k]==1:\n",
    "            cnt=cnt+1\n",
    "#             print(ans_labels[k-1],ans_labels[k],ans_labels[k+1])\n",
    "            if (t==0 or t==5) and k-1>0 and k+1<len(ans_pre) and (ans_labels[k-1]==0 or ans_labels[k+1])==0:\n",
    "                point=point+1\n",
    "            elif ans_labels[k-1]==0 or ans_labels[k+1]==0:\n",
    "                context=context+1\n",
    "            elif ans_labels[k-1]==1 or ans_labels[k+1]==1:\n",
    "                collective=collective+1\n",
    "            \n",
    "#     print(t,cnt)\n",
    "    w=w+10\n",
    "    count_mp[str(t)]=count_mp.get(str(t))+cnt\n",
    "print(count_mp)\n",
    "point,context,collective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d14ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}